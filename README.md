# Python-Amazon-Web-Scraper
# Amazon web scraper project using BeautifulSoup

Stages of the Web Scraper:

- Connect to website we intend to scrape and pull-in data<br>
- Strip the content as part of data cleaning before it is imported into a CSV file<br>
- Create a timestamp, to track when data was collected<br>
- Create the CSV file where scraped files will be collated, write headers and data into file<br>
- Print data from the CSV file we have just created<br>
- Appending new data to the CSV<br>
- We automate the process of price checking. Combine all of above code into one function<br>
- Automated query runs the above query check_price once every day (86,400 seconds) and inputs data into our CSV file we created
